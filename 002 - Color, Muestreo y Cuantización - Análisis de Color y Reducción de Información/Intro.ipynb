{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1JsIQQSfiISqsbc3oY_AQdEUIwGLvlURB","timestamp":1756336834989}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install scikit-image watermark -q"],"metadata":{"id":"qvwM5_awCOOJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756333458687,"user_tz":180,"elapsed":15510,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"7e2d64d3-2e2e-4f18-cd6a-f7b02b2f9b8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.6 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import numpy as np\n","import cv2\n","from cv2 import imread\n","import matplotlib.pyplot as plt"],"metadata":{"id":"lByQpuznEQuI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["[OpenCV](https://opencv.org/) (\"Open Computer Vision\") es una librería de código abierto de visión artificial desarrollada originalmente por Intel. Implementada en `C++` pero con APIs en multiples lenguajes, con soporte multiplataforma, es una de las librerías más populares y utilizadas de computer vision. Incluye una gran cantidad de funcionalidad relacionada a la visión artificial."],"metadata":{"id":"rphC99c_g29E"}},{"cell_type":"markdown","source":["[watermark](https://github.com/rasbt/watermark) es una extensión de las \"magic functions\" de jupyter que permite verificar fácilmente la versión de python y de las librerías instaladas."],"metadata":{"id":"YBsJQeRRTfMV"}},{"cell_type":"code","source":["%load_ext watermark\n","%watermark\n","%watermark --iversions"],"metadata":{"id":"OMEivWjHTUqZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Input Image"],"metadata":{"id":"L7czspYT6O8r"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"YWSd2YwT6K5a"},"outputs":[],"source":["!wget https://d1lfxha3ugu3d4.cloudfront.net/images/opencollection/archives/size2/S03i3165l01.jpg\n","\n","#https://scikit-image.org/docs/stable/api/skimage.data.html#skimage.data.coins\n","#https://opencollection.brooklynmuseum.org/archives/image/51611"]},{"cell_type":"markdown","source":["## Leer y mostrar la imagen"],"metadata":{"id":"o0EAFnAGGZ95"}},{"cell_type":"code","source":["img = imread('S03i3165l01.jpg')\n","plt.imshow(img)\n","plt.show()"],"metadata":{"id":"fyR77wRoAu06"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(img)"],"metadata":{"id":"8BFmOEnwV6yx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Funcion ¿cómo es esta imagen?"],"metadata":{"id":"XCfGOyt8H_3w"}},{"cell_type":"code","source":["def data_img(img):\n","  print('size = ',img.shape)\n","  print('max  = ',np.max(img))\n","  print('min  = ',np.min(img))\n","\n","data_img(img)"],"metadata":{"id":"O-_nmlXTH_hn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["¿Qué son estas dimensiones?\n","\n","La función data_img nos muestra la forma de la imagen a través de img.shape. Esta tupla nos indica las dimensiones de la imagen. Las dos primeras dimensiones corresponden al alto (height) y al ancho (width) de la imagen, respectivamente. Por ejemplo, si img.shape devuelve (305, 200, 3), significa que la imagen tiene 305 pixeles de alto, 200 pixeles de ancho y 3 canales de color (RGB)."],"metadata":{"id":"xnNhYUBvWL28"}},{"cell_type":"markdown","source":["## Recortar / cropear"],"metadata":{"id":"xCaTJRpbHE7P"}},{"cell_type":"code","source":["# Primero alto, despues ancho\n","img_cropped = img[0:80, 300:370]\n","plt.imshow(img_cropped)"],"metadata":{"id":"U-kjO_uFHC4G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_img(img_cropped)"],"metadata":{"id":"jA0EHAT4JPFT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Primero ancho y despues alto\n","img_resize = cv2.resize(img_cropped, (500, 600))\n","plt.imshow(img_resize)"],"metadata":{"id":"aKNiByGVjVzJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Primero ancho y despues alto\n","img_resize = cv2.resize(img_cropped, (500, 600))\n","plt.imshow(img_resize)"],"metadata":{"id":"2Oz2RKvUkagA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Apilado vertical\n","ver = np.vstack((img_resize, img_resize))\n","plt.imshow(ver);"],"metadata":{"id":"vi6AqRvxkmZn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Apilamos horizontamente dos filas, generando una \"matriz\" de 2x2\n","hor2 = np.hstack((ver, ver))\n","plt.imshow(hor2);"],"metadata":{"id":"NjPZkxWJk4KO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Selección del primer canal"],"metadata":{"id":"651-aqtkJiTg"}},{"cell_type":"code","source":["X = img_cropped[:,:,0]\n","data_img(X)"],"metadata":{"id":"ofOdoYcnJlX8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(X,cmap='gray')\n","plt.show()"],"metadata":{"id":"fzGPNzLeqNX6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Para usar esta función llamamos a [`cv2.Canny()`](https://docs.opencv.org/4.x/da/d22/tutorial_py_canny.html). El primer parámetro es la imagen en la que queremos detectar los bordes. El segundo y el tercer parámetro configuran la sensibilidad del algoritmo. Valores típicos son: `(100, 200)`, `(50, 100)`, `(150, 200)`. El tercero debe ser más alto que el primero (uno es un mínimo y otro es un máximo). Valores bajos harán al algoritmo más sensible (esto es, detectará más bordes) y valores más altos harán que detecte menos bordes."],"metadata":{"id":"fx42sghZXJVu"}},{"cell_type":"code","source":["img_canny = cv2.Canny(img_cropped, 200, 250)\n","plt.imshow(img_canny, cmap='gray');"],"metadata":{"id":"DyPLKXxdWkMV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En OpenCV y NumPy, las imágenes a color se almacenan como arrays de 3 dimensiones:\n","\n","* Primera dimensión (altura): número de filas\n","* Segunda dimensión (ancho): número de columnas\n","* Tercera dimensión (canales): 3 valores para BGR (Blue, Green, Red)\n","\n","La notación [:,:,0] utiliza el indexado de NumPy donde:\n","\n","* : significa \"tomar todos los elementos\" de esa dimensión\n","* 0 significa \"tomar solo el primer canal\"\n","\n","Por ejemplo, si tenemos una imagen de 100x200 píxeles:\n","\n","* img_cropped[: , : , 0] - Canal Rojo (primer canal)\n","* img_cropped[: , : , 1] - Canal Verde (segundo canal)\n","* img_cropped[: , : , 2] - Canal Azul (tercer canal)"],"metadata":{"id":"byHBsUxmr6Dg"}},{"cell_type":"code","source":["# Canal Rojo\n","X_red = img_cropped[:,:,1]\n","plt.imshow(X_red, cmap='gray')\n","plt.title('Canal Verde')\n","plt.show()"],"metadata":{"id":"SGfLBBMHrrqi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/BSDS300/html/images/plain/normal/color/124084.jpg"],"metadata":{"id":"2JAxqwRbUXAK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Todo rojo, nada de verde, nada de azul ==> rojo\n","pixel1 = (255, 0, 0)\n","\n","# Todo rojo, todo verde, nada de azul ==> amarillo\n","pixel2 = (0, 255, 0)\n","\n","# Todo rojo, nada verde, todo azul ==> purpura\n","pixel3 = (0, 0, 255)\n","\n","plt.imshow([[pixel1, pixel2, pixel3]]);"],"metadata":{"id":"YdNxL2sHWPIp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img = imread('124084.jpg')\n","plt.imshow(img)\n","plt.show()"],"metadata":{"id":"jhTGFSWHUcpO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"],"metadata":{"id":"_NH4qC9wV5Ar"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img[0, 0]"],"metadata":{"id":"yASlT-3JVM7R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(img_rgb);"],"metadata":{"id":"mh6qhKImV-QE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Thresholding - Segmentación simple"],"metadata":{"id":"ydpyA6UjJ1lI"}},{"cell_type":"code","source":["def segmenta(X,t):\n","    # X: imagen de entrada (matriz 2D)\n","    # t: valor de umbral (threshold)\n","\n","    (N,M) = X.shape  # Obtiene dimensiones de la imagen\n","    Y = np.zeros((N,M))  # Crea matriz de ceros del mismo tamaño\n","    area = 0  # Inicializa contador de píxeles\n","\n","    # Recorre cada píxel de la imagen\n","    for i in range(N):  # Recorre filas\n","        for j in range(M):  # Recorre columnas\n","            if X[i,j] > t:  # Si el píxel supera el umbral\n","                Y[i,j] = 255  # Lo marca como blanco\n","                area = area + 1  # Incrementa el contador\n","\n","    print('area = ',area)  # Imprime área total\n","    return Y  # Devuelve imagen segmentada"],"metadata":{"id":"3girfzB5J1SR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Segmentación"],"metadata":{"id":"-0E1LX0EKAul"}},{"cell_type":"code","source":["# 1. Llamada a la función de segmentación\n","Y = segmenta(X,120)  # Segmenta la imagen usando umbral 120\n","\n","# 2. Analiza las propiedades de la imagen resultante\n","data_img(Y)\n","\n","# 3. Visualiza la imagen segmentada\n","plt.imshow(Y)\n","plt.show()"],"metadata":{"id":"94ETROLsJ9ym"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Todas las monedas"],"metadata":{"id":"cm19I4rbKKzm"}},{"cell_type":"code","source":["full_img = imread('S03i3165l01.jpg')\n","X   = full_img[:,:,0]\n","data_img(X)\n","plt.imshow(X,cmap='gray')\n","plt.show()"],"metadata":{"id":"4e7-i5mKKLMy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y = segmenta(X,100)\n","plt.imshow(Y,cmap='gray')\n","plt.show()"],"metadata":{"id":"CoTyegsgLDfm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y = segmenta(X,150)\n","plt.imshow(Y,cmap='gray')\n","plt.show()"],"metadata":{"id":"fg32STRnNXIU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Definición de un fondo homogéneo"],"metadata":{"id":"cOAU0iWRN1PO"}},{"cell_type":"markdown","source":["El propósito de este código es:\n","\n","* Normalizar la iluminación por filas\n","* Reducir variaciones de fondo\n","* Mejorar el contraste local\n","* Facilitar la segmentación posterior\n","\n","Por ejemplo:\n","\n","Si una fila tiene valores [100, 120, 150] y el mínimo es 100 después de la normalización: [0, 20, 50]\n","\n","Esto es útil cuando:\n","\n","* Hay variaciones de iluminación en la imagen\n","* El fondo no es uniforme\n","* Se necesita resaltar objetos sobre el fondo\n","* Se quiere preparar la imagen para segmentación\n","\n","La imagen resultante tendrá:\n","\n","* Fondo más uniforme\n","* Objetos más destacados\n","* Mejor contraste local\n","* Más facilidad para aplicar umbralización"],"metadata":{"id":"BA2Cp1k2t20V"}},{"cell_type":"code","source":["# 1. Obtiene las dimensiones de la imagen\n","(N,M) = X.shape  # N = número de filas, M = número de columnas\n","\n","# 2. Crea una matriz vacía del mismo tamaño\n","Xm = np.zeros((N,M), np.uint8)  # Matriz de ceros de 8 bits\n","\n","# 3. Procesa cada fila de la imagen\n","for i in range(N):\n","    xmin = np.min(X[i,:])  # Encuentra el valor mínimo de la fila\n","    Xm[i,:] = X[i,:] - xmin  # Resta el mínimo a toda la fila\n","\n","# 4. Visualiza el resultado\n","plt.imshow(Xm, cmap='gray')\n","plt.show()"],"metadata":{"id":"uZHC4SuFODZ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y = segmenta(Xm,140)\n","plt.imshow(Y,cmap='gray')\n","plt.show()"],"metadata":{"id":"k1w5k_rTOJeD"},"execution_count":null,"outputs":[]}]}